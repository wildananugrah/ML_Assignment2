{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, 7, 5, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train = pd.read_csv(\"dataset/train_features.csv\")\n",
    "y_train = pd.read_csv(\"dataset/train_labels.csv\")\n",
    "X_test = pd.read_csv(\"dataset/valid_features.csv\")\n",
    "y_test = pd.read_csv(\"dataset/valid_labels.csv\")\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=[\"loudness\",\"title\",\"tempo\", \"time_signature\",\"key\",\"mode\",\"duration\"])\n",
    "X_test = pd.DataFrame(X_test, columns=[\"loudness\",\"title\",\"tempo\", \"time_signature\",\"key\",\"mode\",\"duration\"])\n",
    "\n",
    "cleanup_nums = {\"genre\": \n",
    "                {\"classic pop and rock\": 1, \n",
    "                 \"dance and electronica\": 2,\n",
    "                 \"folk\":3,\n",
    "                 \"jazz and blues\":4,\n",
    "                 \"metal\":5,\n",
    "                 \"pop\":6,\n",
    "                 \"punk\":7,\n",
    "                 \"soul and reggae\":8\n",
    "                }}\n",
    "y_train.replace(cleanup_nums, inplace=True)\n",
    "y_test.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_title_cv_train = tfidf_vect.fit_transform(X_train['title'])\n",
    "df_title_cv_train = pd.DataFrame(X_title_cv_train.toarray(), columns=tfidf_vect.get_feature_names())\n",
    "X_train = pd.concat([X_train, df_title_cv_train], axis=1)\n",
    "X_train = X_train.drop([\"title\"], 1)\n",
    "\n",
    "X_title_cv_test = tfidf_vect.transform(X_test['title'])\n",
    "df_title_cv_test = pd.DataFrame(X_title_cv_test.toarray(), columns=tfidf_vect.get_feature_names())\n",
    "X_test = pd.concat([X_test, df_title_cv_test], axis=1)\n",
    "X_test = X_test.drop([\"title\"], 1)\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler.fit(X_train)\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "X_train['time_signature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaion report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.75      0.25        55\n",
      "           2       0.19      0.11      0.14        45\n",
      "           3       0.40      0.19      0.26        64\n",
      "           4       0.00      0.00      0.00        44\n",
      "           5       0.59      0.15      0.24        66\n",
      "           6       0.83      0.34      0.48        74\n",
      "           7       0.17      0.11      0.14        44\n",
      "           8       0.25      0.17      0.20        58\n",
      "\n",
      "    accuracy                           0.24       450\n",
      "   macro avg       0.32      0.23      0.21       450\n",
      "weighted avg       0.37      0.24      0.23       450\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[41  3  4  0  1  1  1  4]\n",
      " [30  5  1  0  2  0  1  6]\n",
      " [40  3 12  0  1  0  1  7]\n",
      " [29  3  5  0  0  0  1  6]\n",
      " [40  3  4  0 10  0  7  2]\n",
      " [36  2  1  0  0 25  7  3]\n",
      " [29  2  2  0  0  4  5  2]\n",
      " [31  6  1  0  3  0  7 10]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41  3  4  0  1  1  1  4]\n",
      " [30  5  1  0  2  0  1  6]\n",
      " [40  3 12  0  1  0  1  7]\n",
      " [29  3  5  0  0  0  1  6]\n",
      " [40  3  4  0 10  0  7  2]\n",
      " [36  2  1  0  0 25  7  3]\n",
      " [29  2  2  0  0  4  5  2]\n",
      " [31  6  1  0  3  0  7 10]]\n",
      "accuracy: 0.24\n",
      "accuracy by sklearn.metric: 0.24\n",
      "precision: [0.14855072 0.18518519 0.4        0.         0.58823529 0.83333333\n",
      " 0.16666667 0.25      ]\n",
      "recall: [0.74545455 0.11111111 0.1875     0.         0.15151515 0.33783784\n",
      " 0.11363636 0.17241379]\n",
      "F1: [0.24773414 0.13888889 0.25531915 0.         0.24096386 0.48076923\n",
      " 0.13513514 0.20408163]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wildan/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "y_train[\"genre\"] = y_train[\"genre\"].astype('int')\n",
    "knn.fit(X_train, y_train[\"genre\"])\n",
    "preds=knn.predict(X_test)\n",
    "\n",
    "# let's how our model performed\n",
    "print(\"Classificaion report: \\n\")\n",
    "print(classification_report(y_test[\"genre\"], preds))\n",
    "print(\"Confusion matrix: \\n\")\n",
    "print(confusion_matrix(y_test[\"genre\"], preds))\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "def evaluate(pred, true):\n",
    "    CM = metrics.confusion_matrix(true, pred) # Confusion Matrix\n",
    "    Acc = metrics.accuracy_score(true, pred) # Accuracy\n",
    "    precf1 = metrics.precision_recall_fscore_support(true, pred) # Precision, Recall and F1-score\n",
    "    return CM, Acc, precf1\n",
    "\n",
    "CM, Acc, precf1 = evaluate(preds, y_test[\"genre\"])\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    correct = correct + int(preds[i]==y_test[\"genre\"][i])\n",
    "    \n",
    "print(\"Confusion Matrix:\\n{}\\naccuracy: {}\\naccuracy by sklearn.metric: {}\\nprecision: {}\\nrecall: {}\\nF1: {}\\n\".format(\n",
    "                                                CM,\n",
    "                                                correct / len(y_test), \n",
    "                                                Acc,\n",
    "                                                precf1[0],\n",
    "                                                precf1[1],\n",
    "                                                precf1[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
